#! /usr/bin/env python

"""\
%prog <refdir> [<ipolfile>=ipol.dat] [opts]

Use the interpolations stored in <ipolfile> to find optimised parameters with
the reference histograms found in the <refdir> as the optimisation target.

TODO:
 * Handle run combination file/string (write a hash of the run list into the ipol filename?)
"""

import optparse, os, sys
op = optparse.OptionParser(usage=__doc__)
op.add_option("--wfile", dest="WFILE", default=None, help="Path to a weight file to specify unequal chi2 weights of each bin in the fit (default: %default)")
op.add_option("--output", dest="OUTPUT", default="tunes", help="Prefix for outputs (default: %default)")
# TODO: ipol fit limits are in the ipol datfile... automatically use them / warn if result is outside?
op.add_option("--limits", dest="LIMITS", default=None, help="Simple text file with parameter limits and fixed parameters")
# TODO: Really a core feature? Define "pull". REMOVE
# op.add_option("--pulls", dest="PULLS", action="store_true", default=False, help="Output pull histograms after minimisation")
# TODO: Add weight file parsing to decide which histos (and bin subsets) to interpolate
op.add_option("--debug", dest="DEBUG", action="store_true", default=False, help="Turn on some debug messages")
op.add_option("--quiet", dest="QUIET", action="store_true", default=False, help="Turn off messages")
opts, args = op.parse_args()

## Get mandatory arguments
if len(args) < 1:
    print "Argument missing... exiting\n\n"
    op.print_usage()
    sys.exit(1)
REFDIR = args[0]
IFILE = "ipol.dat"
if len(args) >= 2:
    IFILE = args[1]


## Load Professor and show the standard banner
import professor2 as prof
if not opts.QUIET:
    print prof.logo


## Read persisted interpolations to re-create the ipol Histos
metadata, IHISTOS = prof.read_ipolhistos(IFILE)


## Read reference data histos
import os, sys, glob
HISTOS = {}
reffiles = glob.glob(os.path.join(REFDIR,  "*"))
for rf in reffiles:
    HISTOS.update(prof.read_histos(rf))

## Weight file parsing
matchers = prof.read_pointmatchers(opts.WFILE) if opts.WFILE else None


## Find things available in both ipol and ref data, and in the weight file if there is one
available = []
for ihn in IHISTOS.keys():
    ## Set default bin weights
    for ib in IHISTOS[ihn].bins:
        ib.w = 1.0
    ## Find user-specified bin weights if there was a weight file
    if matchers is not None:
        ## Find matches
        pathmatch_matchers = [(m,wstr) for m,wstr in matchers.iteritems() if m.match_path(ihn)]
        ## Ditch histos not listed in the weight file
        if not pathmatch_matchers:
            del IHISTOS[ihn]
            continue
        ## Attach fit weights to the ibins, setting to zero if there's no position match
        for ib in IHISTOS[ihn].bins:
            posmatch_matchers = [(m,wstr) for (m,wstr) in pathmatch_matchers if m.match_pos(ib)]
            ib.w = float(posmatch_matchers[-1][1]) if posmatch_matchers else 0 #< NB. using last match
    for rhn in HISTOS.keys():
        if ihn in rhn: #< short for rhn = "/REF/"+ihn ?
            available.append([ihn,rhn])
            break #< TODO: ok?


## Prepare lists of ibins and dbins
ibins, dbins = [], []
for a in available:
    # TODO: print out the available observables
    #print a, len(IHISTOS[a[0]].bins) == len(HISTOS[a[1]].bins)
    ibins.extend(IHISTOS[a[0]].bins)
    dbins.extend( HISTOS[a[1]].bins)

## Sanity checks
assert(len(ibins) == len(dbins))
if not ibins:
    print "No bins ..., exiting"
    sys.exit(1)


def simpleGOF(params):
    """
    Very straightforward goodness-of-fit measure
    """
    chi2 = 0.0
    for num, ibin in enumerate(ibins):
        ## Weight is attached to the ipol bin (default to 1.0)
        w = ibin.w if hasattr(ibin, "w") else 1.0
        ## Get ipol & ref bin values and compute their difference
        ival = ibin.val(params)
        dval = dbins[num].val
        diff = dval - ival
        ## Data error
        err2 = dbins[num].err**2
        ## Plus interpolation error added in quadrature
        err2 += ibin.err(params)**2 # TODO: compute asymm error for appropriate deviation direction cf. sum([e**2 for e in ibin.ierrs])
        if not err2:
            raise prof.StatError("Zero uncertainty on a bin being used in the fit -- cannot compute a reasonable GoF")
        # TODO: should we square w too, so it penalised deviations _linearly_?
        chi2 += w * diff**2 / err2
    return chi2


## Take parameter names directly from ifile
mpnames = [x.replace("^","").replace("lambda", "llambda") for x in metadata["ParamNames"].split()]
## Fallback solution if empty
if not mpnames:
    mpnames = ["MP%03i" % (i) for i in xrange(int(metadata["Dimension"]))]

## Function definition wrapper
funcdef = prof.mk_fitfunc("simpleGOF", mpnames)
exec funcdef in locals()
if opts.DEBUG:
    print "Built GoF wrapper from:\n  '%s'" % funcdef


## Ignition
minuit = prof.Minuit(profGoF)
minuit.strategy = 2

## Starting point --- use center
# TODO: Optionally make an initial brute force scan to choose the Minuit starting point
C = []
for num, m in enumerate(map(float, metadata["MinParamVals"].split())):
    C.append(m + 0.5*(float(metadata["MaxParamVals"].split()[num])-m)) #< TODO: there's got to be a nicer way...
for num, name in enumerate(mpnames):
    minuit.values[name] = C[num]

## Fix parameters, set limits
limits, fixed = prof.read_limitsandfixed(opts.LIMITS)
for mp in mpnames:
    if mp in limits.keys():
        minuit.limits[mp] = limits[mp]
    if mp in fixed.keys():
        minuit.values[mp] = fixed[mp]
        minuit.fixed[mp] = True

## Lift off
minuit.migrad()

## Goodness of fit
if not opts.QUIET:
    chi2 = minuit.fval
    ndof = len(dbins) - len(mpnames) + len(fixed.keys())
    # TODO: improve... chi2/Ndf isn't the GoF
    print "'chi2': %.2f" % chi2
    print "Ndf   : %i" % ndof
    # print "G.o.F.: %.2f \n" % (chi2, chi2/ndof)


## Check if result is in validity range
result = [minuit.values[p] for p in mpnames]
rng_low = map(float, metadata["MinParamVals"].split())
rng_high = map(float, metadata["MaxParamVals"].split())
rok, rng = prof.is_inrange(result, rng_low, rng_high)


## Print results to screen
for num, p in enumerate(mpnames):
    isl, isf = " ", " "
    if opts.QUIET:
        print "%s\t%f"%(p, minuit.values[p])
    else:
        if p in fixed.keys():
            isf = "F"
        if p in limits.keys():
            isl = "L"
        if rok or not num in rng:
            print "%s\t%f\t%f\t%.2f %%   inside  (%f --- %f) %s %s"%(p, minuit.values[p], minuit.errors[p], 100*(minuit.errors[p]/minuit.values[p]), rng_low[num], rng_high[num], isf, isl)
        else:
            print "%s\t%f\t%f\t%.2f %%  OUTSIDE (%f --- %f) %s %s"%(p, minuit.values[p], minuit.errors[p], 100*(minuit.errors[p]/minuit.values[p]), rng_low[num], rng_high[num], isf, isl)


## Write out result
with open("%s_results.txt" % opts.OUTPUT,"w") as f:
    ## Meta info
    f.write("# ProfVersion: %s\n" % prof.mk_versionstring())
    f.write("# Date: %s\n" % prof.mk_timestamp())
    f.write("# InterpolationFile: %s\n" % os.path.abspath(IFILE))
    # TODO: weights --- dump them all or just the file name? for consistency, probably better to dump them all at the end
    ## Limits
    lstring = ""
    for p in mpnames:
        if limits.has_key(p):
            lstring += "#\t%s\t%f %f\n"%(p, limits[p][0], limits[p][1])
    f.write("# Limits: \n%s" % lstring)
    # Fixed parameters
    fstring = ""
    for p in mpnames:
        if fixed.has_key(p):
            fstring += "#\t%s\t%f\n" % (p, fixed[p])
    f.write("# Fixed: \n%s" % fstring)

    ## The tuned parameter values
    for p in mpnames:
        f.write("%s\t%f\n" % (p, minuit.values[p]))


## Write out ipolhistos
result = [minuit.values[name] for name in mpnames]
with open("%s_ipolhistos.yoda" % opts.OUTPUT, "w") as f:
    for num, k in enumerate(sorted(IHISTOS.keys())):
        f.write(IHISTOS[k].toDataHisto(result).toYODA())
        if num+1 < len(IHISTOS.keys()):
            f.write("\n")


# ## Pull histograms
# if opts.PULLS:
#     pulls = []
#     for a in available:
#         ikey=a[0]
#         dkey=a[1]
#         ib = IHISTOS[ikey].bins
#         db =  HISTOS[dkey].bins
#         pb = []
#         for i in xrange(len(ib)):
#             py = prof.pull(db[i], ib[i], result)
#             pb.append(prof.DataBin(db[i].xmin, db[i].xmax, py, 0))
#         pulls.append(prof.Histo(pb, ikey))

#     with open("%s_pulls.yoda"%opts.OUTPUT, "w") as f:
#         [f.write(h.toYODA()) for h in pulls]
