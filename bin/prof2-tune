#! /usr/bin/env python

"""\
%prog <refdir> [<ipolfile>=ipol.dat] [<runsdir>=<refdir>/../mc] [opts]

Use the interpolations stored in <ipolfile> to find optimised parameters with
the reference histograms found in the <refdir> as the optimisation target.

The <runsdir> is used to calculate the maximum error value seen for each bin,
to regularise interpolated errors which could otherwise blow up, leading to
an unrepresentative small chi2 (and hence fit result) outside the sampled ranges.

TODO:
 * Handle run combination file/string (write a hash of the run list into the ipol filename?)
"""

import optparse, os, sys
op = optparse.OptionParser(usage=__doc__)
op.add_option("--wfile", dest="WFILE", default=None, help="Path to a weight file to specify unequal chi2 weights of each bin in the fit (default: %default)")
op.add_option("--output", dest="OUTPUT", default="tunes", help="Prefix for outputs (default: %default)")
op.add_option("--limits", dest="LIMITS", default=None, help="Simple text file with parameter limits and fixed parameters")
# TODO: Add weight file parsing to decide which histos (and bin subsets) to interpolate
op.add_option("--debug", dest="DEBUG", action="store_true", default=False, help="Turn on some debug messages")
op.add_option("--quiet", dest="QUIET", action="store_true", default=False, help="Turn off messages")
opts, args = op.parse_args()

## Get mandatory arguments
if len(args) < 1:
    print "Argument missing... exiting\n\n"
    op.print_usage()
    sys.exit(1)
REFDIR = args[0]
IFILE = "ipol.dat"
RUNSDIR = os.path.join(REFDIR, "..", "mc")
if len(args) >= 2:
    IFILE = args[1]
if len(args) >= 3:
    RUNSDIR = args[2]


# TODO: ipol fit limits are in the ipol datfile... automatically use them / warn if result is outside?


## Load Professor and show the standard banner
import professor2 as prof
from professor2 import ui
if not opts.QUIET:
    print prof.ui.logo


## Read persisted interpolations to re-create the ipol Histos
METADATA, IHISTOS = prof.ui.read_ipolhistos(IFILE)

## Read reference data histos
import os, sys, glob
DHISTOS = {}
REFFILES = glob.glob(os.path.join(REFDIR, "*"))
for rf in REFFILES:
    DHISTOS.update(prof.ui.read_histos(rf))

## Try to read run histos and extract maximum errors
MAXERRDICT = None
try:
    rundirs = glob.glob(os.path.join(RUNSDIR, "*"))
    _, RUNHISTOS = prof.ui.read_rundata(rundirs, None) #< don't care about reading params files
    MAXERRDICT = prof.ui.find_maxerrs(RUNHISTOS)
except:
    print "Could not read run data for error regularisation -- chi2 may be unstable"

## Weight file parsing
matchers = prof.ui.read_pointmatchers(opts.WFILE) if opts.WFILE else None


## Find things available in both ipol and ref data, and in the weight file if there is one
available = []
for ihn in IHISTOS.keys():
    ## Set default bin weights
    for ib in IHISTOS[ihn].bins:
        ib.w = 1.0
    ## Find user-specified bin weights if there was a weight file
    if matchers is not None:
        ## Find matches
        pathmatch_matchers = [(m,wstr) for m,wstr in matchers.iteritems() if m.match_path(ihn)]
        ## Ditch histos not listed in the weight file
        if not pathmatch_matchers:
            del IHISTOS[ihn]
            continue
        ## Attach fit weights to the ibins, setting to zero if there's no position match
        for ib in IHISTOS[ihn].bins:
            posmatch_matchers = [(m,wstr) for (m,wstr) in pathmatch_matchers if m.match_pos(ib)]
            ib.w = float(posmatch_matchers[-1][1]) if posmatch_matchers else 0 #< NB. using last match
    for rhn in DHISTOS.keys():
        if ihn in rhn: #< TODO: short for rhn = "/REF/"+ihn ?
            # TODO: we should eliminate this potential mismatch of ref and MC hnames
            available.append([ihn,rhn])
            break #< TODO: ok?


## Prepare lists of ibins and dbins
IBINS, DBINS, MAXERRS = [], [], []
for a in available:
    # TODO: print out the available observables
    IBINS.extend(IHISTOS[a[0]].bins)
    DBINS.extend(DHISTOS[a[1]].bins)
    if MAXERRDICT:
        MAXERRS.extend(MAXERRS[a[0]])
if not MAXERRS:
    MAXERRS = None


## Sanity checks
assert len(IBINS) == len(DBINS)
if not IBINS:
    print "No bins ..., exiting"
    sys.exit(1)
assert MAXERRS is None or len(IBINS) == len(MAXERRS)


def simpleGoF(params):
    """
    Very straightforward goodness-of-fit measure
    """
    chi2 = 0.0
    for num, ibin in enumerate(IBINS):
        ## Weight is attached to the ipol bin (default to 1.0)
        w = ibin.w if hasattr(ibin, "w") else 1.0
        ## Get ipol & ref bin values and compute their difference
        ival = ibin.val(params)
        dval = DBINS[num].val
        diff = dval - ival
        ## Data error
        err2 = DBINS[num].err**2
        ## Plus interpolation error added in quadrature
        maxierr = MAXERRS[ibin] if MAXERRS else None
        err2 += ibin.err(params, emax=maxierr)**2
        # TODO: compute asymm error for appropriate deviation direction cf. sum([e**2 for e in ibin.ierrs])
        if not err2:
            raise prof.ui.StatError("Zero uncertainty on a bin being used in the fit -- cannot compute a reasonable GoF")
        # TODO: should we square w too, so it penalised deviations _linearly_?
        chi2 += w * diff**2 / err2
    return chi2


## Take parameter names directly from ifile, or fallback
PNAMES = METADATA["ParamNames"].split()
if not PNAMES:
    PNAMES = ["A%03i" % i for i in xrange(int(METADATA["Dimension"]))]

## Function definition wrapper
funcdef, ANAMES = prof.ui.mk_fitfunc("simpleGoF", PNAMES)
exec funcdef in locals()

#from IPython import embed
#embed()

if opts.DEBUG:
    print "Built GoF wrapper from:\n  '%s'" % funcdef
print "Parameter translation:"
for i in xrange(len(PNAMES)):
    print " ", PNAMES[i], "->", ANAMES[i]


try:
    from iminuit import Minuit
except ImportError, e:
    print "Unable to import iminuit, exiting", e
    import sys
    sys.exit(1)

## Ignition
# This is a dummy for now
dumminuit = Minuit(simpleGoF, pedantic=False, print_level=2)#, forced_parameters=pnames)
# Dummy fitargs
FARG=dumminuit.fitarg

## Initial conditions --- use pos = center of hypercube, and step = range/10
# TODO: Optionally make an initial brute force scan to choose the Minuit starting point, using prof.scangrid
pmins = [float(x) for x in METADATA["MinParamVals"].split()]
pmaxs = [float(x) for x in METADATA["MaxParamVals"].split()]
assert len(pmins) == len(pmaxs)
pmids = [(pmins[i] + pmaxs[i])/2. for i in xrange(len(pmins))]
pranges = [(pmaxs[i] - pmins[i]) for i in xrange(len(pmins))]
for i, aname in enumerate(ANAMES):
    FARG[aname] = pmids[i]
    FARG['error_%s'%aname] = pranges[i] / 10.

## Fix parameters, set limits (with pname translation)
limits, fixed = prof.ui.read_limitsandfixed(opts.LIMITS)

for i, pname in enumerate(PNAMES):
    aname=ANAMES[i]
    if pname in limits.keys():
        FARG['limit_%s'%aname] = limits[pname]
    if pname in fixed.keys():
        print "Fixing", pname, "= %f"%fixed[PNAMES[i]]
        FARG[aname] = fixed[PNAMES[i]]
        FARG['fix_%s'%aname] = True


FARG.pop('error_params')
FARG.pop('params')
FARG.pop('fix_params')
FARG.pop('limit_params')
# TODO: errordef, strategy CL params?
minuit = Minuit(profGoF, errordef=1, forced_parameters=ANAMES, **FARG)
minuit.strategy = 0
## Lift off
minuit.migrad()


### Now process the result:
## Goodness of fit
if not opts.QUIET:
    chi2 = minuit.fval
    ndof = len(DBINS) - (len(PNAMES) - len(fixed.keys()))
    print "chi2: %.2f" % chi2
    print "Ndf : %i" % ndof

## Check if result is in validity range
result = [minuit.values[a] for a in ANAMES]
rok, rng = prof.ui.is_inrange(result, pmins, pmaxs)

## Print results to screen
for num, p in enumerate(PNAMES):
    isl, isf = " ", " "
    if opts.QUIET:
        print "%s\t%f" % (p, minuit.values[ANAMES[num]])
    else:
        if p in fixed.keys() or ANAMES[num] in fixed.keys():
            isf = "F"
        if p in limits.keys():
            isl = "L"
        in_out = " inside" if (rok or not num in rng) else "OUTSIDE"
        print "%s\t%f\t%f\t%.2f %%   %s  (%f --- %f) %s %s" % (p, minuit.values[ANAMES[num]], minuit.errors[ANAMES[num]],
                                                               100*(minuit.errors[ANAMES[num]]/minuit.values[ANAMES[num]]),
                                                               in_out, pmins[num], pmaxs[num], isf, isl)
#from IPython import embed
#embed()

## Write out result
with open("%s_results.txt" % opts.OUTPUT,"w") as f:
    ## Meta info
    f.write("# ProfVersion: %s\n" % prof.ui.mk_versionstring())
    f.write("# Date: %s\n" % prof.ui.mk_timestamp())
    f.write("# InterpolationFile: %s\n" % os.path.abspath(IFILE))
    f.write("# DataDirectory: %s\n" % os.path.abspath(REFDIR))
    # TODO: weights --- dump them all or just the file name? for consistency, probably better to dump them all at the end
    ## Limits
    lstring = ""
    for p in PNAMES:
        if limits.has_key(p):
            lstring += "\n#\t%s\t%f %f" % (p, limits[p][0], limits[p][1])
    f.write("#\n# Limits: %s" % lstring)
    # Fixed parameters
    fstring = ""
    for p in PNAMES:
        if fixed.has_key(p):
            fstring += "\n#\t%s\t%f" % (p, fixed[p])
    f.write("\n#\n# Fixed: %s\n" % fstring)
    f.write("#\n# Minimisation result:\n#\n")
    ## The tuned parameter values
    for i, p in enumerate(PNAMES):
        f.write("%s\t%f\n" % (p, minuit.values[ANAMES[i]]))


## Write out ipolhistos TODO catch import error?
import yoda
result = [minuit.values[name] for name in ANAMES]
scatters=[IHISTOS[k].toDataHisto(result).toScatter2D() for k in sorted(IHISTOS.keys())]
yoda.writeYODA(scatters, "%s_ipolhistos.yoda" % opts.OUTPUT)
